<!--timestamp:1543726800-->

# Injecting Files into an Archive Format I Don‚Äôt Understand

![](https://cdn-images-1.medium.com/max/800/1*T7TfUmcwFixUuRx-9CHp2g.png)

Somewhat recently I was a part of the group reverse engineering files for smash ultimate, and one of the problems we encountered is that we were figuring out just about every file type faster than the 14 gigabyte archive they were contained. This creates an interesting scenario of a lot of code being written, but little to no testing done. Feeling antsy about wanting to try some modifications on hardware, I decided to try to figure out a temporary solution to help us get by.

## Extracting Files

Talking about injecting files into an archive is getting a bit ahead of ourselves if we don‚Äôt even know what the files we‚Äôre replacing look like. So how do you *extract* files from an archive format you don‚Äôt understand? Well, in this case the giveaway is compression.

In this case, our archive uses zstandard compression, a compression algorithm developed by facebook, for a majority of its files. One question I get quite frequently is ‚ÄúHow do you figure out compressed data?‚Äù Here‚Äôs what my process tends to look like:

1. Look for ‚Äúmagic‚Äù, or data at the beginning (or, on rare occasions, the end) that is constant and used to indicate what a block of data is, this is pretty common practice both for files and compression types. In the case of zstandard, we have a magic of ‚Äú28 B5 2F FD‚Äù, which when googled yeilds:

![](https://cdn-images-1.medium.com/max/2000/1*yGTD3s1ezlj7A_FMlCVENQ.png)

which pretty much tells us all we need to know (encoding = ‚Äòzstd‚Äô). With enough exposure, recognizable magics like zlib‚Äôs will be possible to pick out without even thinking about it.

2. Look at the environment. Do you have a copy of the binary that would be parsing these? Check for imports to see if it‚Äôs using a system or dynamic library provided decompression algorithm, sometimes it‚Äôll be as simple as finding ‚Äúlz4.dll‚Äù sitting beside the executable. Have no information other than what type of machine it runs on? Look for developer documentation on the system to see what types of compression have implementations provided to the system. Worst comes to worst, find the code for parsing the file by other means and figure it out using static analysis and pray it‚Äôs not custom.

![Simplified view of a zstandard compressed block](https://cdn-images-1.medium.com/max/2000/1*II_a-kNslowpo9iYH5EXiA.png)*Simplified view of a zstandard compressed block*

Now we know how to find all the compressed files with somewhat reasonable accuracy: search for the magic, parse the header data of zstd to find the compressed size, then copy it out to a file. Or‚Ä¶ if you‚Äôre lazy like me just see that the files are back to back for the most part (see image below) and choose to just split the files by the magic and hope not too many files break.

![Search results for zstd magic](https://cdn-images-1.medium.com/max/2000/1*zRc-4KqsgjwOkmsulMOLbQ.png)*Search results for zstd magic*

## Injecting Files

Now we have some (tens of thousands of) filename-less files and we use tools like grep to find the one we want to modify (Note: it‚Äôs worth mentioning that using file magic to separate files by type makes this a lot easier to work with). From here we figure out the file format, modify some data and now we want to put it back in. Some assumptions we can make:

1. Somewhere in the archive the size of the file compressed (and likely uncompressed as well) is stored.

1. There is may be a sanity check by hashing the file and comparing to a hash stored in the archive (not common, but often used in things like save formats as they are written multiple times and this ensures they aren‚Äôt loading an unintentionally corrupt save)

1. (Only because I learned this in the process of extracting) Zstandard stores info in the compressed data‚Äôs header about the size of the compressed file. For many zstd implementations, including extra bytes on the end may raise an exception, ending our fun and in this case closing the game.

Knowing this, we gain our constraints:
1. The compressed and uncompressed file sizes must remain the same

2. (Self enforced) our data must functionally remain the same.

To figure this out we‚Äôll have to look at the fundamental idea of compression. Let‚Äôs take a look at how two pieces of data would be compressed by a hypothetical compression method

    Data 1
    ------
    00 00 00 00  ->  00 repeated 04 times

    Data 2
    ------
    01 02 03 04  ->  01 repeated 01 time, 02 repeated 01 time, 03 repeated 01 time, 04 repeated 01 time

So we take the same number of bytes, use the same compression method on them and, while the data with a lot of repeating bytes compresses by 50%, the data with no repetition doubles in size. While every type of compression is different in one way or another, for the most part repetition = better compression.

### Injecting Level Data

Now let‚Äôs look at how I did my first level data injection, shown in this tweet:

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">First smash ultimate compressed archive mod and first stage mod afaik <a href="https://t.co/k1lx8QAkVM">https://t.co/k1lx8QAkVM</a><br><br>Thanks to <a href="https://twitter.com/Raytwo_ssb?ref_src=twsrc%5Etfw">@Raytwo_ssb</a> for testing and recording, luckily it only took one try üòé</p>&mdash; jam1garner (@jam1garner) <a href="https://twitter.com/jam1garner/status/1066826227527364608?ref_src=twsrc%5Etfw">November 25, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

The mod itself is changing three floats (decimal values) in the file. One float of the y coordinate of a point in the collision, one float of the lower y bound of the camera box, and one float of the lower y bound of the death boundary.

![Visualization of the tested mod](https://cdn-images-1.medium.com/max/2398/1*f8BHhVzBQBzChwRt7HosAA.jpeg)*Visualization of the tested mod*

Now we need to somehow make the file compress to the exact same size as before without changing anything functionally. To do so I choose to modify the float values. Let‚Äôs take a look at two float values to see why this works:

    1.00 - 00 00 80 3F
    1.01 - AE 47 81 3F

So, generally speaking, more precision in our floats means it‚Äôs more random, and therefore less compressible. With that information, we‚Äôll be able to make small adjustments to floats in order to nudge the compressed size up and down. The other adjustment we control is what level of compression we use. Typically, in compression, the level of compression is a trade off between time to compress/decompress and the compressed size of the file. So if we increase the compression level, the file will become more and more compressed, allowing for our minor edits to have more of an effect. With this we can tweak compression level until it‚Äôs as close to our original size as we can get, and then make floats more or less precise to slightly tweak our file size until it matches the original.

### Injecting a texture (Hard mode)

Injecting a texture, which I eventually did, (see tweet below) turned out to be much more of a challenge.

<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">Here&#39;s the first (afaik) texture edit in smash ultimate, texture edit by <a href="https://twitter.com/KillzXGaming?ref_src=twsrc%5Etfw">@KillzXGaming</a>, injected into the game by me <a href="https://t.co/58t0o59dhb">pic.twitter.com/58t0o59dhb</a></p>&mdash; jam1garner (@jam1garner) <a href="https://twitter.com/jam1garner/status/1068255268293746695?ref_src=twsrc%5Etfw">November 29, 2018</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

With textures, there‚Äôs not only a lot more data that isn‚Äôt free for us to tweak, but due to a lot of repeated use of the same color (and therefore the same bytes), it compresses a lot more. And since we have to modify a lot more than 12 bytes to make a meaningful texture edit, it means we won‚Äôt be starting from a point that is close to the original compressed file size. Even after adjusting the compression level, the closest I could get was still over a KB away, and at compression level 1 (the worst case scenario for this technique) no less! This meant I would have to find a large area to have control of without messing up how the texture looks. In the end I ended up settling on the smallest ‚Äúmip map‚Äù or texture level of detail.

![Mip maps visualized](https://cdn-images-1.medium.com/max/2000/1*8MRyTA9MsJxkkAqY1xaGXw.png)*Mip maps visualized*

So mip maps are more or less just prerendered downscaled versions of a texture included within the texture file for when the object is low res enough of the screen that the full resolution of the texture isn‚Äôt needed. Since the lowest level mip will only be used with the texture is a couple pixels on the screen, modifying this won‚Äôt affect the user experience. So in this case, I just replace the mipmap‚Äôs texture data with any data I want, and adjust that data until the file size matches using a similar technique to before.

## Conclusion

While this certainly isn‚Äôt the best solution to the problem of wanting to replace files, mainly due to its context-specific requirements being hard to generalize (what if a file needs to be byte perfect? won‚Äôt work), it has its benefits as a quick and dirty solution that doesn‚Äôt really require understanding the archive. (Not to mention being a fun challenge).

Questions/Comments/More? My twitter: [https://www.twitter.com/jam1garner](https://www.twitter.com/jam1garner)
